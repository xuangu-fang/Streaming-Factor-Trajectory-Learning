{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def process_to_txt(dataset_name):\n",
    "\n",
    "    dict_name = '../for_matlab/'+dataset_name+'/'\n",
    "    Path(dict_name).mkdir(parents=True, exist_ok=True)\n",
    "    data_file = '../' + dataset_name + '.npy'\n",
    "    full_data = np.load(data_file, allow_pickle=True).item()\n",
    "\n",
    "    for fold in range(5):\n",
    "        \n",
    "        data_dict = full_data['data'][fold]\n",
    "        data_dict['ndims'] = full_data['ndims'] \n",
    "        data_dict['ndims'] = full_data['ndims'] +[len(full_data['time_uni'])]\n",
    "\n",
    "        data_dict['tr_ind'] = np.concatenate([data_dict['tr_ind'],data_dict['tr_T_disct'].reshape(-1,1)],1)\n",
    "        data_dict['te_ind'] = np.concatenate([data_dict['te_ind'],data_dict['te_T_disct'].reshape(-1,1)],1)\n",
    "\n",
    "        train_data = np.concatenate([data_dict['tr_ind'],data_dict['tr_y']],1)\n",
    "        test_data = np.concatenate([data_dict['te_ind'],data_dict['te_y']],1)\n",
    "\n",
    "        fmt = ['%d' for i in range(len(data_dict['ndims']))] + ['%.3f']\n",
    "\n",
    "        file_train = dict_name + dataset_name+ \"_train_\" + str(fold) + '.txt'\n",
    "        file_test = dict_name + dataset_name+ \"_test_\" + str(fold) + '.txt'\n",
    "\n",
    "        np.savetxt(file_train,train_data,fmt=fmt,delimiter=' ')\n",
    "        np.savetxt(file_test,test_data,fmt=fmt,delimiter=' ')\n",
    "\n",
    "    ndims_info = 'dataset: %s, ndims: %s'%(dataset_name, str(data_dict['ndims'])) \n",
    "\n",
    "    f= open(dict_name + 'ndims.txt',\"w+\")\n",
    "    f.write(ndims_info)\n",
    "    f.write(\"\\n  base-0 indexing, space-separated, last-column is entry values, last-mode is DDT-mode (use for static baseline, drop for streaming baselines), all entries ordered by DDT-mode (last mode)\")\n",
    "\n",
    "# dataset_name = 'beijing_15k'\n",
    "# dataset_name = 'beijing_20k'\n",
    "# dataset_name = 'traffic_48k'\n",
    "# dataset_name = 'server_10k'\n",
    "\n",
    "process_to_txt('beijing_15k')\n",
    "process_to_txt('beijing_20k')\n",
    "process_to_txt('traffic_48k')\n",
    "process_to_txt('server_10k')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2b9b245c32fdd00062c065bea1c6c406b1fa841caa084ac758573a37ef3ce19"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('pytorch_1.10.1': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}