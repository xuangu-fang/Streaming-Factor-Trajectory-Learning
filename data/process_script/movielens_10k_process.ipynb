{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 987]\n"
     ]
    }
   ],
   "source": [
    "data_file = '../../../data/movielens/mv_10k.npy'\n",
    "# data_file = '../../../data/clickthrough/ctr_10k.npy'\n",
    "# data_file = '../../../data/server/server_10k.npy'\n",
    "\n",
    "\n",
    "# data_file = '../data/'\n",
    "raw_data = np.load(data_file, allow_pickle=True).item()\n",
    "print(raw_data.get('ndims'))\n",
    "data = raw_data.get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "tr_ind = data[0]['tr_ind']\n",
    "tr_y = data[0]['tr_y']\n",
    "tr_T = data[0]['tr_T']\n",
    "\n",
    "te_ind = data[0]['te_ind']\n",
    "te_y = data[0]['te_y']\n",
    "te_T = data[0]['te_T']\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "all_ind = np.concatenate((tr_ind,te_ind))\n",
    "all_time = np.concatenate((tr_T,te_T)) # zheng has alreadly normalized the time into 0-1\n",
    "all_y = np.concatenate((tr_y,te_y))\n",
    "\n",
    "all_data['location'] = all_ind[:,0].astype(np.int64)\n",
    "all_data['pollutant'] = all_ind[:,1].astype(np.int64)\n",
    "# all_data['period'] = all_ind[:,2].astype(np.int64)\n",
    "all_data['y'] = all_y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(np.round(all_time,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no never-seen time-stamp in test data\n"
     ]
    }
   ],
   "source": [
    "decimal = 3\n",
    "\n",
    "all_time = np.round(all_time,decimal)\n",
    "\n",
    "all_data['time'] = all_time\n",
    "\n",
    "\n",
    "time_uni_all = np.sort(np.unique(all_time))\n",
    "time_uni_tr = np.sort(np.unique(all_time))\n",
    "\n",
    "if len(time_uni_all)==len(time_uni_tr):\n",
    "    print('no never-seen time-stamp in test data')\n",
    "else: print('exist never-seen time-stamp in test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim of time is 398\n"
     ]
    }
   ],
   "source": [
    "def unique_recoding(data,colum_name):\n",
    "    # colum_name = 'movieId'\n",
    "    unique_key = np.sort(data[colum_name].unique())\n",
    "    recode_dict = {key:id for id,key in enumerate(unique_key)}\n",
    "\n",
    "    new_column = data[colum_name].apply(lambda x:recode_dict[x])\n",
    "    # data[colum_name] = new_column\n",
    "    print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
    "    return recode_dict, new_column\n",
    "\n",
    "def unique_recoding_array(data_array):\n",
    "    \n",
    "    unique_key = np.unique(data_array)\n",
    "    recode_dict = {key:id for id,key in enumerate(unique_key)}\n",
    "\n",
    "    new_array =  np.array(list(map(lambda x:recode_dict[x], data_array)))\n",
    "    # data[colum_name] = new_column\n",
    "    # print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
    "    return new_array\n",
    "\n",
    "recode_dict_globle,all_data['timestamp_disct'] = unique_recoding(all_data,'time') \n",
    "# use for baseline, where we simply encoding the timastamp as extra mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = {}\n",
    "data_save['ndims'] = raw_data.get('ndims')\n",
    "data_save['num_node'] = np.sum(data_save['ndims'])\n",
    "data_save['data'] = []\n",
    "data_save['time_uni'] = np.sort(np.unique(all_time)) # sorted unique timestamps of all data\n",
    "data_save['time_id_table'] = recode_dict_globle # timestamp-disct id map table\n",
    "\n",
    "for fold in range(5):\n",
    "\n",
    "    fold_data = {}\n",
    "    tr_ind = data[fold]['tr_ind']\n",
    "    tr_y = data[fold]['tr_y']\n",
    "    tr_T = np.round(data[fold]['tr_T'],decimal)\n",
    "\n",
    "    te_ind = data[fold]['te_ind']\n",
    "    te_y = data[fold]['te_y']\n",
    "    te_T = np.round(data[fold]['te_T'],decimal)\n",
    "\n",
    "    # we have to sort the training data by the time-stamp\n",
    "    # also sort the test data, but it's not necessary\n",
    "    tr_sort_id = np.argsort(np.squeeze(tr_T))\n",
    "    fold_data['tr_ind'] = tr_ind[tr_sort_id,:].astype(int)\n",
    "    fold_data['tr_y'] = tr_y[tr_sort_id]\n",
    "    fold_data['tr_T'] = tr_T[tr_sort_id]\n",
    "\n",
    "    te_sort_id = np.argsort(np.squeeze(te_T))\n",
    "    fold_data['te_ind'] = te_ind[te_sort_id,:].astype(int)\n",
    "    fold_data['te_y'] = te_y[te_sort_id]\n",
    "    fold_data['te_T'] = te_T[te_sort_id]\n",
    "\n",
    "    # we discrete the time-stamps of all data(both train and test),and encoding them with id\n",
    "    # there are two usages of this feature:\n",
    "    # 1: use them as extra mode in some non-dynamict baselines  \n",
    "    # 2: to efficient identify the group of obseved entries with same time-stamps\n",
    "\n",
    "    fold_data['tr_T_disct'] = np.array(list(map(lambda x:recode_dict_globle[x], np.squeeze(fold_data['tr_T'])))).astype(int)\n",
    "    fold_data['te_T_disct'] = np.array(list(map(lambda x:recode_dict_globle[x], np.squeeze(fold_data['te_T'])))).astype(int)\n",
    "\n",
    "    data_save['data'].append(fold_data)\n",
    "    \n",
    "file_name = '../mvlens_10k.npy'\n",
    "np.save(file_name, data_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1.10.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4adb47148028defd32b9bf0fd4ba8fab9423764bcb932d46181929557b860185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
