{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 20, 50]\n",
      "3\n",
      "(33379, 5)\n",
      "(16599, 5)\n"
     ]
    }
   ],
   "source": [
    "data_file = '../../../data/fitRecord/processed/FitRecInterp.pickle'\n",
    "# data_file = '../data/'\n",
    "raw_data = np.load(data_file, allow_pickle=True)\n",
    "print(raw_data['nvec'])\n",
    "print(raw_data['nmod'])\n",
    "train_data_list = raw_data['train_folds']\n",
    "test_data_list = raw_data['test_folds']\n",
    "print(train_data_list[0].shape)\n",
    "print(test_data_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no never-seen time-stamp in test data\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "tr_ind = train_data_list[fold][:,0:3]\n",
    "tr_y = train_data_list[fold][:,-1]\n",
    "tr_T = train_data_list[fold][:,-2]\n",
    "\n",
    "te_ind =  test_data_list[fold][:,0:3]\n",
    "te_y =  test_data_list[fold][:,-1]\n",
    "te_T =  test_data_list[fold][:,-2]\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "all_ind = np.concatenate((tr_ind,te_ind))\n",
    "all_time = np.concatenate((tr_T,te_T)) # zheng has alreadly normalized the time into 0-1\n",
    "all_y = np.concatenate((tr_y,te_y))\n",
    "\n",
    "# standardize the y\n",
    "all_y = (all_y - all_y.mean()) / all_y.std()\n",
    "\n",
    "all_data['location'] = all_ind[:,0].astype(np.int64)\n",
    "all_data['pollutant'] = all_ind[:,1].astype(np.int64)\n",
    "# all_data['period'] = all_ind[:,2].astype(np.int64)\n",
    "all_data['y'] = all_y.astype(float)\n",
    "all_data['time'] = all_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decimal = 2\n",
    "\n",
    "all_time = np.round(all_time,decimal)\n",
    "\n",
    "all_data['time'] = all_time\n",
    "\n",
    "\n",
    "time_uni_all = np.sort(np.unique(all_time))\n",
    "time_uni_tr = np.sort(np.unique(all_time))\n",
    "\n",
    "\n",
    "if len(time_uni_all)==len(time_uni_tr):\n",
    "    print('no never-seen time-stamp in test data')\n",
    "else: print('exist never-seen time-stamp in test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim of time is 101\n"
     ]
    }
   ],
   "source": [
    "def unique_recoding(data,colum_name):\n",
    "    # colum_name = 'movieId'\n",
    "    unique_key = np.sort(data[colum_name].unique())\n",
    "    recode_dict = {key:id for id,key in enumerate(unique_key)}\n",
    "\n",
    "    new_column = data[colum_name].apply(lambda x:recode_dict[x])\n",
    "    # data[colum_name] = new_column\n",
    "    print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
    "    return recode_dict, new_column\n",
    "\n",
    "def unique_recoding_array(data_array):\n",
    "    \n",
    "    unique_key = np.unique(data_array)\n",
    "    recode_dict = {key:id for id,key in enumerate(unique_key)}\n",
    "\n",
    "    new_array =  np.array(list(map(lambda x:recode_dict[x], data_array)))\n",
    "    # data[colum_name] = new_column\n",
    "    # print('ndim of %s is %d'%(colum_name,len(new_column.unique())))\n",
    "    return new_array\n",
    "\n",
    "recode_dict_globle,all_data['timestamp_disct'] = unique_recoding(all_data,'time') \n",
    "# use for baseline, where we simply encoding the timastamp as extra mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = {}\n",
    "data_save['ndims'] = raw_data['nvec']\n",
    "data_save['num_node'] = np.sum(data_save['ndims'])\n",
    "data_save['data'] = []\n",
    "data_save['time_uni'] = np.sort(np.unique(all_time)) # sorted unique timestamps of all data\n",
    "data_save['time_id_table'] = recode_dict_globle # timestamp-disct id map table\n",
    "\n",
    "N = len(all_y)\n",
    "ratio = 0.8\n",
    "N_train = int(N*ratio)\n",
    "\n",
    "for fold in range(5):\n",
    "\n",
    "    fold_data = {}\n",
    "\n",
    "    idx = np.random.permutation(N)\n",
    "    train_idx = idx[:N_train]\n",
    "    test_idx = idx[N_train:]\n",
    "\n",
    "    tr_ind = all_ind[train_idx,:]\n",
    "    tr_y = all_y[train_idx]\n",
    "    tr_T = all_time[train_idx]\n",
    "\n",
    "    te_ind =  all_ind[test_idx,:]\n",
    "    te_y =  all_y[test_idx]\n",
    "    te_T =  all_time[test_idx]\n",
    "\n",
    "\n",
    "    # we have to sort the training data by the time-stamp\n",
    "    # also sort the test data, but it's not necessary\n",
    "    tr_sort_id = np.argsort(np.squeeze(tr_T))\n",
    "    fold_data['tr_ind'] = tr_ind[tr_sort_id,:].astype(int)\n",
    "    fold_data['tr_y'] = tr_y[tr_sort_id]\n",
    "    fold_data['tr_T'] = tr_T[tr_sort_id]\n",
    "\n",
    "    te_sort_id = np.argsort(np.squeeze(te_T))\n",
    "    fold_data['te_ind'] = te_ind[te_sort_id,:].astype(int)\n",
    "    fold_data['te_y'] = te_y[te_sort_id]\n",
    "    fold_data['te_T'] = te_T[te_sort_id]\n",
    "\n",
    "    # we discrete the time-stamps of all data(both train and test),and encoding them with id\n",
    "    # there are two usages of this feature:\n",
    "    # 1: use them as extra mode in some non-dynamict baselines  \n",
    "    # 2: to efficient identify the group of obseved entries with same time-stamps\n",
    "\n",
    "    fold_data['tr_T_disct'] = np.array(list(map(lambda x:recode_dict_globle[x], np.squeeze(fold_data['tr_T'])))).astype(int)\n",
    "    fold_data['te_T_disct'] = np.array(list(map(lambda x:recode_dict_globle[x], np.squeeze(fold_data['te_T'])))).astype(int)\n",
    "    data_save['data'].append(fold_data)\n",
    "\n",
    "    \n",
    "file_name = '../fitRecord_50k.npy'\n",
    "np.save(file_name, data_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0,\n",
       " 0.01: 1,\n",
       " 0.02: 2,\n",
       " 0.03: 3,\n",
       " 0.04: 4,\n",
       " 0.05: 5,\n",
       " 0.06: 6,\n",
       " 0.07: 7,\n",
       " 0.08: 8,\n",
       " 0.09: 9,\n",
       " 0.1: 10,\n",
       " 0.11: 11,\n",
       " 0.12: 12,\n",
       " 0.13: 13,\n",
       " 0.14: 14,\n",
       " 0.15: 15,\n",
       " 0.16: 16,\n",
       " 0.17: 17,\n",
       " 0.18: 18,\n",
       " 0.19: 19,\n",
       " 0.2: 20,\n",
       " 0.21: 21,\n",
       " 0.22: 22,\n",
       " 0.23: 23,\n",
       " 0.24: 24,\n",
       " 0.25: 25,\n",
       " 0.26: 26,\n",
       " 0.27: 27,\n",
       " 0.28: 28,\n",
       " 0.29: 29,\n",
       " 0.3: 30,\n",
       " 0.31: 31,\n",
       " 0.32: 32,\n",
       " 0.33: 33,\n",
       " 0.34: 34,\n",
       " 0.35: 35,\n",
       " 0.36: 36,\n",
       " 0.37: 37,\n",
       " 0.38: 38,\n",
       " 0.39: 39,\n",
       " 0.4: 40,\n",
       " 0.41: 41,\n",
       " 0.42: 42,\n",
       " 0.43: 43,\n",
       " 0.44: 44,\n",
       " 0.45: 45,\n",
       " 0.46: 46,\n",
       " 0.47: 47,\n",
       " 0.48: 48,\n",
       " 0.49: 49,\n",
       " 0.5: 50,\n",
       " 0.51: 51,\n",
       " 0.52: 52,\n",
       " 0.53: 53,\n",
       " 0.54: 54,\n",
       " 0.55: 55,\n",
       " 0.56: 56,\n",
       " 0.57: 57,\n",
       " 0.58: 58,\n",
       " 0.59: 59,\n",
       " 0.6: 60,\n",
       " 0.61: 61,\n",
       " 0.62: 62,\n",
       " 0.63: 63,\n",
       " 0.64: 64,\n",
       " 0.65: 65,\n",
       " 0.66: 66,\n",
       " 0.67: 67,\n",
       " 0.68: 68,\n",
       " 0.69: 69,\n",
       " 0.7: 70,\n",
       " 0.71: 71,\n",
       " 0.72: 72,\n",
       " 0.73: 73,\n",
       " 0.74: 74,\n",
       " 0.75: 75,\n",
       " 0.76: 76,\n",
       " 0.77: 77,\n",
       " 0.78: 78,\n",
       " 0.79: 79,\n",
       " 0.8: 80,\n",
       " 0.81: 81,\n",
       " 0.82: 82,\n",
       " 0.83: 83,\n",
       " 0.84: 84,\n",
       " 0.85: 85,\n",
       " 0.86: 86,\n",
       " 0.87: 87,\n",
       " 0.88: 88,\n",
       " 0.89: 89,\n",
       " 0.9: 90,\n",
       " 0.91: 91,\n",
       " 0.92: 92,\n",
       " 0.93: 93,\n",
       " 0.94: 94,\n",
       " 0.95: 95,\n",
       " 0.96: 96,\n",
       " 0.97: 97,\n",
       " 0.98: 98,\n",
       " 0.99: 99,\n",
       " 1.0: 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recode_dict_globle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu_1.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ac3df537db5f3d3ebece04625d4a144692b0f9760967bb0d0cff1c13eb4a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
